API automation for event type counts:
1. Tuples ? what are the indexes? what column does it refer to?
2. wiki page update productType case sensitive, and default
3. Query for processedRejected, processedAccepted and processedDeleted
-----------------------------------------------------------------
API automation for fileStatus:
1. why not equals for error message comparision. **** because we are appending some other message to what we got.
2. equals actual vs expected. ***
3. test data for 79 
4. Should be Sorted by upload timestamp . And what if they are same ???? Currently I am doing by name next
5. For latest ProcessingDate, the results for 79 is usually empty list
6. Remove env=dev from check in

//API currently only sorts by upload timestamp descending, So to compare the results we are implementing our own comparator
Collections.sort(actualFileStatusInfo.getFileStatusDetailOutputs(), new FileStatusDetailOutputComparator());
7. Update submitterId to uploadOrgId -> Comprehensive stats too.

-------------------------------------------------------------------------------------------------------
REPORTER:
	1. Get memberDictionaryList for last 90 days
	2. Get IMIDs from that

SUBMITTER:
	1.  Get memberDictionaryList for last 90 days
	2.  Get OSO realationship for last 90 days for submitterId=LoggedInUser
	3. For every relationship, and memberDictionaryList, if(imidFromOso=ImidFromMember AND reporterOrgForOso=CrdFromMember ) -> add to imids


Relationship gives Reporters whose IMID we need to lookup in memberDictionary table.....

SELECT distinct imid FROM catdd_owner.mstr_mbr_dict_hs where firm_crd_nb=79
Union 
Select distinct cat_rprtr_imid from catdd_owner.oso_rltnp_hs where cat_sbmtr_id=79 AND actv_fl=true
order by imid asc;


------------------------------------------------------------------------------------------------------------
72.7

//    @Test
//    public void testBuildWhereClauseForDerivedColumns_NotNullRepairedStatus_NotNullGroupRepairEligibility()
//    {
//        assertEquals(" WHERE  info.rprd_smry = :repairedStatus2 AND  grp_rpr_fl = :groupRepairEligible",
//            eventDao.buildWhereClauseForDerivedColumns(RepairedStatusEnum.PENDING, true));
//    }

    @Test
    public void testBuildWhereClauseForDerivedColumns_NullRepairedStatus_NotNullGroupRepairEligibility()
    {
        assertEquals(" WHERE  grp_rpr_fl = :groupRepairEligible", eventDao.buildWhereClauseForDerivedColumns(null, true));
    }

    @Test
    public void testGetTotalCountErrorSummaryDetails()
    {
        Long mock = mock(Long.class);
        ArgumentCaptor<String> queryCaptor = ArgumentCaptor.forClass(String.class);
        ArgumentCaptor<Map<String, Object>> parameterMapCaptor = ArgumentCaptor.forClass(Map.class);
        when(eventQueries.getQueryValues(anyString())).thenReturn("%s|%s|%s|%s");
        when(namedParameterJdbcTemplate.queryForObject(anyString(), anyMap(), mock)).thenReturn(1200L);
        Long totalCount = errorSummaryDao
            .getTotalCountErrorSummaryDetails(ORG_ID, CAT_REPORTER_IMID, DateTypeEnum.PROCESSING_DATE, DATE, ProductTypeEnum.ALL, PerspectiveEnum.SUBMITTER,
                COLUMN_NAME_ENUM_LIST, FILTER_TYPE_ENUM_LIST, COMPARE_TYPE_ENUM_LIST, FILTER_VALUE_LIST);
        assertEquals(Long.valueOf(1200), totalCount);
        assertEquals(QUERY_GET_TOTAL_COUNT, queryCaptor.getValue());
//        verify(namedParameterJdbcTemplate).query(anyString(), anyMap(), Long.class);
    }
-----------------------------------
PendingEvents:																									86.7

 "sortModel": [
    {
      "colId": "catReporterIndustryMemberId",
      "sort": "desc"
    },
     {
      "colId": "errorCount",
      "sort": "asc"
    }
   ],
   
   
   "type": {
           "filterType": "text",
           "type": "equals",
           "filter": "NEW"
       },
        "errorRoeId": {
           "filterType": "number",
           "type": "equals",
           "filter": 10004
       },
        "quoteId": {
           "filterType": "text",
           "type": "equals",
           "filter": "54"
       },
        "orderId": {
           "filterType": "text",
           "type": "equals",
           "filter": "OrderID_4"
       }
-----------------------------------
ErrorSearch:
    
	"catReporterIndustryMemberId": {
           "filterType": "text",
           "type": "equals",
           "filter": "D"
       },
          "errorRoeId": {
           "filterType": "number",
           "type": "equals",
           "filter": 500004
       },
          "firmRoeId": {
           "filterType": "text",
           "type": "equals",
           "filter": "60004"
       },
          "errorCode": {
           "filterType": "text",
           "type": "equals",
           "filter": "2041"
       },
          "errorReason": {
           "filterType": "text",
           "type": "equals",
           "filter": "Missing or Invalid manualFlag"
       },
          "errorType": {
           "filterType": "text",
           "type": "equals",
           "filter": "Rejection"
       },
          "repairedStatus": {
           "filterType": "text",
           "type": "equals",
           "filter": "R"
       },
          "quoteKeyDate": {
           "filterType": "text",
           "type": "equals",
           "filter": "2020-05-04"
       }
	   
  },
    "sortModel": [
    {
      "colId": "quoteKeyDate",
      "sort": "desc"
    },
     {
      "colId": "errorType",
      "sort": "asc"
    }
   ],
----------------------------------------------------------------------------------------
Things need to do:(2020-01-13)
Unit tests 
COlumn sort filter,,multiple ***
Add security
Validations 
ERROR SUMMARY:

  "filterModel": {
      "errorCount": {
           "filterType": "number",
           "type": "equals",
           "filter": 1
       },
      "catReporterIndustryMemberId": {
           "filterType": "text",
           "type": "equals",
           "filter": "A"
       },
      "date": {
           "filterType": "date",
           "type": "equals",
           "filter": "2019-12-10"
       },
  
      "errorType": {
           "filterType": "text",
           "type": "equals",
           "filter": "Rejection"
       },
      "repairedStatus": {
           "filterType": "text",
           "type": "equals",
           "filter": "U"
       },
	  "catSubmitterId": {
           "filterType": "number",
           "type": "equals",
           "filter": 13
       },
	  "groupRepairEligible": {
           "filterType": "text",
           "type": "equals",
           "filter": "Y"
       },
	  "errorReason": {
           "filterType": "text",
           "type": "equals",
           "filter": "Missing or Invalid fulfillmentLinkType"
       },
	  "errorCode": {
           "filterType": "number",
           "type": "equals",
           "filter": 2041
       }
	   
  },
    "sortModel": [
    {
      "colId": "errorType",
      "sort": "desc"
    },
     {
      "colId": "catSubmitterId",
      "sort": "asc"
    }
   ],
  
  -------------------------------------------------------------------------- 
           StringBuilder whereClauseOuter = new StringBuilder(256);
        StringBuilder whereClauseOuterConditions = new StringBuilder(256);
        String havingClause = "";
        if (CollectionUtils.isNotEmpty(columnNameEnumFilterList) && CollectionUtils.isNotEmpty(filterTypeEnumList) && CollectionUtils.isNotEmpty(compareTypeEnumList)
            && CollectionUtils.isNotEmpty(filterValueList))
        {
            for(int i=0; i<columnNameEnumFilterList.size(); i++)
            {
                if (StringUtils.equals(columnNameEnumFilterList.get(i).getValue(), ColumnNameEnum.ERROR_COUNT.getValue()))
                {
                    havingClause = buildHavingClause(columnNameEnumFilterList.get(i));
                }
                else
                {
                    whereClauseOuterConditions.append(buildWhereClauseOuter(columnNameEnumFilterList.get(i)));
                    if(i < (columnNameEnumFilterList.size()-1) && !Objects.equals(columnNameEnumFilterList.get(i).getValue(), ColumnNameEnum.ERROR_COUNT))
                    {
                        whereClauseOuterConditions.append(" AND");
                    }
                    if(i == (columnNameEnumFilterList.size()-1))
                    {
                        whereClauseOuter.append(" WHERE").append(whereClauseOuterConditions);
                    }
                }
            }
        }
		
		    protected Pair<String, String> buildWhereAndHavingClauseOuter(List<ColumnNameEnum> columnNameEnumFilterList, List<FilterTypeEnum> filterTypeEnumList,
        List<CompareTypeEnum> compareTypeEnumList, List<Object> filterValueList)
    {
        StringBuilder whereClauseOuter = new StringBuilder(256);
        StringBuilder whereClauseOuterConditions = new StringBuilder(256);
        String havingClause = "";

        if (CollectionUtils.isNotEmpty(columnNameEnumFilterList) && CollectionUtils.isNotEmpty(filterTypeEnumList) &&
            CollectionUtils.isNotEmpty(compareTypeEnumList) && CollectionUtils.isNotEmpty(filterValueList))
        {
            Boolean isWhereRequired = false;
            for (int i = 0; i < columnNameEnumFilterList.size(); i++)
            {
                if (StringUtils.equals(columnNameEnumFilterList.get(i).getValue(), ColumnNameEnum.ERROR_COUNT.getValue()))
                {
                    havingClause = buildHavingClause(columnNameEnumFilterList.get(i));
                }
                else
                {
                    whereClauseOuterConditions.append(buildWhereClauseOuterConditions(columnNameEnumFilterList.get(i)));
                    //never reaches array out of bound
                    if (i < (columnNameEnumFilterList.size() - 1) &&
                        !StringUtils.equals(columnNameEnumFilterList.get(i + 1).getValue(), ColumnNameEnum.ERROR_COUNT.getValue()))
                    {
                        whereClauseOuterConditions.append(" AND");
                    }
                    isWhereRequired = true;
                }
            }
            if (isWhereRequired)
            {
                whereClauseOuter.append(" WHERE").append(whereClauseOuterConditions);
            }
        }
        return new Pair<>(havingClause, whereClauseOuter.toString());
    }
	
------------------------------------------------------------------------------------------

	INSERT INTO catco_owner.err_rec_dtl(
	err_roe_id, cat_rprtr_imid, actn_type, firm_roe_id, msg_type, odr_key_dt, odr_id, sym, prnt_odr_key_dt, prnt_odr_id, orgng_imid, event_ts, side, pr, qty, min_qty, odr_type, tif, trdg_sssn, hndlg_instr, seq_nb, ats_dsply_ind, dsply_pr, wrkng_pr, dsply_qty, nbb_pr, nbb_qty, nbo_pr, nbo_qty, nbbo_src, nbbo_ts, cncl_qty, lvs_qty, rsrvd_for_fut_use, prior_odr_key_dt, prior_odr_id, fill_key_dt, flmnt_id, prior_fill_key_dt, prior_flmnt_id, mnl_fl, elctc_ts, cpcty, flmnt_link_type, clnt_dtl, firm_dtl, dept_type, rcvng_desk_type, info_barr_id, elctc_dplct_fl, mnl_odr_key_dt, mnl_odr_id, cstmr_dsply_ind_fl, firm_dsgnt_id, accnt_hldr_type, afflt_fl, agrtd_odrs, ngttd_trd_fl, rep_ind, ats_odr_type, quote_key_dt, quote_id, prior_quote_key_dt, prior_quote_id, sndr_imid, dstnt, rtd_quote_id, only_one_quote_fl, bid_pr, bid_qty, ask_pr, ask_qty, usltd_ind, mp_stts_cd, quote_rjctd_fl, rcvr_imid, sndr_type, rtd_odr_id, iso_ind, inttr, cncl_fl, cncl_ts, dstnt_type, sssn, route_rjctd_fl, dup_roid_cond, trd_key_dt, trd_id, tape_trd_id, mkt_cntr_id, side_dtl_ind, buy_dtl, sll_dtl, rptg_xcptn_cd, rcvd_quote_id, quote_wntd_ind, optn_id, opn_cls_ind, prior_unlkd, next_unlkd, exch_orgn_cd, ats_odr_type_elmnt, raw_data, crtd_ts)
	VALUES (500001, 'A', 'action1', '60001', 'type1', '2020-02-21', 'order1', 'symbol1', 'parentOrderKey1', 'parentOrderId1', 'orgImid1', '2020-08-21 07:36:44', 'side1', 'pr1', '1', '1', 'orderTyp1', 'tif1', 'session1', 'handling1', 'seq1', 'atsD1', 'dsp1', 'w1', '1', 'nbb1', '1', 'nbo1', 1, 'src1', '2020-08-21 06:36:44', '1', '1', '1', '2020-07-01', 'priorOrdId1', '2020-05-01', 'flmn1', '2020-03-01', 'priorFlm1', 'mnl1', '2020-08-21 08:36:44', '1', 'link1', 'clnt1', 'firmDtl1', 'dept1', 'rvbng1', 'infoBar1', 'elctc1', '2020-08-01', 'mnl1', 'fl1', 'firmDsg1', 'accHldr1', 'aff1', 'agrOrd1', 'ngtdd1', 'rep1', 'atsOdr1', '2020-05-01', 'quote1', '2020-05-01', 'prrQo1', 'sndr1', 'dstnt1', 'rtd1', 'only1', 'bid1', '1', 'ask1', '1', 'usltd1', 'mp1', 'quote1', 'rcvr1', 'sndrTy1', 'rtdOdr1', 'iso1', 'int1', 'cnclFl1', '2020-08-21 08:36:44', 'dstnType1', 'sesson1', 'route1', 'dup1', '2020-04-01', 'trd1', 'tape1', 'mktCnt1', 'side1', 'buy1', 'sll1', 'rptg1', 'rcvd1', 'quoteWind1', 'optnId1', 'opnCls1', 'prUnl1', 'nxtUnl1', 'exch1', 'atsElem1', 'raw1', '2020-08-21 07:36:44');
			

------------------------------------------------------------------------------------------

INSERT INTO catco_owner.err_rec_info(
	err_roe_id, cat_rprtr_id, cat_rprtr_imid, cat_sbmtr_id, sbmtr_3rd_prty, file_nm, file_frmt, prcsg_dt, trd_dt, event_type, prdct_type, rprd_st, err_type, actn_type, firm_roe_id, err_list, msg_type, crtd_ts, crtd_by, updtd_ts, updtd_by, rpr_type_cd, rpr_ts, rpr_user_id, crctn_due_ts)
	VALUES ('500001', 22, 'A', 22, 123, 'fileName', 'fileformat', '2019-01-01', '2019-01-01', 'MENO', 'Options', 'R', 'Rejection', 'aaaa', '20191218_101-MONO-No-Error', 'errList', 'messag', '2019-08-22 11:36:44', 'user1', '2019-08-22 11:36:44', 'user2', 'Corrected1', '2019-11-11', 'dummyRepair1', '2019-12-22 11:36:44');
	

-------------------------------------------------------------------------------------------
SELECT err_cd, err_ds, grp_rpr_elgbl, rec_fld, crtd_ts, crtd_by, updtd_ts, updtd_by
	FROM catdd_owner.err_cd_lk;
	
INSERT INTO catdd_owner.err_cd_lk(
	err_cd, err_ds, grp_rpr_elgbl, rec_fld, crtd_ts, crtd_by, updtd_ts, updtd_by)
	VALUES (1011, 'Some error message', true, 'aaaa', '2019-04-04', 'user1', '2019-04-04', 'user2');
	
-------------------------------------------------------------------------------------------
SELECT err_roe_id, err_cd, err_value, crtd_ts, crtd_by, updtd_ts, updtd_by
	FROM catdd_owner.err_rec_cd;
	
INSERT INTO catdd_owner.err_rec_cd(
	err_roe_id, err_cd, err_value, crtd_ts, crtd_by, updtd_ts, updtd_by)
	VALUES ('15300', 2001, 'Missing or Invalid accountHolderType', '2019-04-04', 'user1', '2019-04-04', 'user2');
	
delete from catdd_owner.err_rec_cd where err_roe_id='12353';
-------------------------------------------------------------------------------------------

SELECT err_roe_id, cat_rprtr_id, cat_rprtr_imid, cat_sbmtr_id, sbmtr_3rd_prty, file_nm, file_frmt, prcsg_dt, trd_dt, event_type, prdct_type, rprd_st, err_type, actn_type, firm_roe_id, err_list, msg_type, crtd_ts, crtd_by, updtd_ts, updtd_by
	FROM catdd_owner.err_rec_info;

Delete from catdd_owner.err_rec_info where err_roe_id='12353';

INSERT INTO catdd_owner.err_rec_info(
	err_roe_id, cat_rprtr_id, cat_rprtr_imid, cat_sbmtr_id, sbmtr_3rd_prty, file_nm, file_frmt, prcsg_dt, trd_dt, event_type, prdct_type, rprd_st, err_type, actn_type, firm_roe_id, err_list, msg_type, crtd_ts, crtd_by, updtd_ts, updtd_by)
	VALUES ('15300', 79, 'SUNNY', 79, 123, 'fileName', 'fileformat', '2019-01-01', '2019-01-01', 'MENO', 'Options', 'P', 'Rejection', 'aaaa', '20191205_101-MONO-No-Error', 'errList', 'messag', '2019-08-22 11:36:44', 'user1', '2019-08-22 11:36:44', 'user2');
-------------------------------------------------------------------------------------------
SELECT pndng_rec_id, cat_rprtr_id, cat_rprtr_imid, cat_sbmtr_id, sbmtr_3rd_prty, actn_type, err_roe_id, firm_roe_id, msg_type, odr_key_dt, odr_id, sym, prnt_odr_key_dt, prnt_odr_id, orgng_imid, event_ts, side, pr, qty, min_qty, odr_type, tif, trdg_sssn, hndlg_instr, seq_nb, ats_dsply_ind, dsply_pr, wrkng_pr, dsply_qty, nbb_pr, nbb_qty, nbo_pr, nbo_qty, nbbo_src, nbbo_ts, cncl_qty, lvs_qty, rsrvd_for_fut_use, prior_odr_key_dt, prior_odr_id, fill_key_dt, flmnt_id, prior_fill_key_dt, prior_flmnt_id, mnl_fl, elctc_ts, cpcty, flmnt_link_type, clnt_dtl, firm_dtl, dept_type, rcvng_desk_type, info_barr_id, elctc_dplct_fl, mnl_odr_key_dt, mnl_odr_id, cstmr_dsply_ind_fl, firm_dsgnt_id, accnt_hldr_type, afflt_fl, agrtd_odrs, ngttd_trd_fl, rep_ind, ats_odr_type, quote_key_dt, quote_id, prior_quote_key_dt, prior_quote_id, sndr_imid, dstnt, rtd_quote_id, only_one_quote_fl, bid_pr, bid_qty, ask_pr, ask_qty, usltd_ind, mp_stts_cd, quote_rjctd_fl, rcvr_imid, sndr_type, rtd_odr_id, iso_ind, inttr, cncl_fl, cncl_ts, dstnt_type, sssn, route_rjctd_fl, dup_roid_cond, trd_key_dt, trd_id, tape_trd_id, mkt_cntr_id, side_dtl_ind, buy_dtl, sll_dtl, rptg_xcptn_cd, rcvd_quote_id, quote_wntd_ind, optn_id, opn_cls_ind, prior_unlkd, next_unlkd, exch_orgn_cd, ats_odr_type_elmnt, rprd_st, crtd_by, crtd_ts, updtd_by, updtd_ts, rec_rprtr_imid
	FROM catdd_owner.pndng_rec;
	
SELECT count(*) from information_schema.columns where table_name='pndng_rec';

SELECT column_name from information_schema.columns where table_name='pndng_rec' order by column_name asc;

delete from catdd_owner.pndng_rec where pndng_rec_id=33

update catdd_owner.pndng_rec set err_roe_id=15200 where pndng_rec_id=35


-------------------------------------------------------------------------------------------
package org.finra.catdd.service.impl;

import java.time.LocalDate;
import java.time.LocalTime;
import java.util.List;

import org.apache.commons.lang3.StringUtils;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import org.springframework.util.Assert;

import org.finra.catdd.common.enums.DateTypeEnum;
import org.finra.catdd.common.enums.PerspectiveEnum;
import org.finra.catdd.common.enums.ProductTypeEnum;
import org.finra.catdd.common.helper.PerspectiveHelper;
import org.finra.catdd.common.utils.CatddDateUtils;
import org.finra.catdd.dao.ErrorSummaryDao;
import org.finra.catdd.dao.HerdDao;
import org.finra.catdd.dao.helper.DateHelper;
import org.finra.catdd.model.dto.ErrorSummaryDetail;
import org.finra.catdd.model.dto.ErrorSummaryDetails;
import org.finra.catdd.model.dto.ErrorSummaryPostRequest;
import org.finra.catdd.model.dto.ErrorSummaryRequest;
import org.finra.catdd.model.dto.ErrorSummaryResponse;
import org.finra.catdd.service.ErrorSummaryService;

/**
 * The implementation class for {@link ErrorSummaryService}
 */
@Service
public class ErrorSummaryServiceImpl implements ErrorSummaryService
{
    @Autowired
    private ErrorSummaryDao errorSummaryDao;

    @Autowired
    private PerspectiveHelper perspectiveHelper;

    @Autowired
    private HerdDao herdDao;

    @Autowired
    private DateHelper dateHelper;

    @Value("${processingDate.cutOff.hour}")
    private Integer processingDateCutOffHour;

    @Value("${processingDate.cutOff.minute}")
    private Integer processingDateCutOffMinute;

    @Value("${processingDate.cutOff.second}")
    private Integer processingDateCutOffSecond;

    @Value("${processingDate.cutOff.nanoOfSecond}")
    private Integer processingDateCutOffNanoOfSecond;

    @Override
    public ErrorSummaryResponse getErrorSummary(ErrorSummaryPostRequest errorSummaryPostRequest)
    {
        Assert.notNull(errorSummaryPostRequest, "The error summary request must not be null.");
        Assert.notNull(errorSummaryPostRequest.getStartRow(), "The error summary parameter \"startRow\" must be specified.");
        Assert.notNull(errorSummaryPostRequest.getEndRow(), "The error summary parameter \"endRow\" must be specified.");
        Assert.notNull(errorSummaryPostRequest.getErrorSummary(), "The error summary filter parameters must not be null.");
        ErrorSummaryRequest errorSummaryRequest = errorSummaryPostRequest.getErrorSummary();
        Assert.notNull(errorSummaryRequest.getCatOrganizationId(), "The parameter \"catOrganizationId\" must be specified.");

        DateTypeEnum dateTypeEnum =
            StringUtils.isEmpty(errorSummaryRequest.getDateType()) ? DateTypeEnum.PROCESSING_DATE : DateTypeEnum.find(errorSummaryRequest.getDateType());

        ProductTypeEnum productTypeEnum =
            StringUtils.isEmpty(errorSummaryRequest.getProductType()) ? ProductTypeEnum.ALL : ProductTypeEnum.find(errorSummaryRequest.getProductType());

        PerspectiveEnum perspectiveEnum = perspectiveHelper.getPerspectiveEnum(errorSummaryRequest.getPerspective());

        validateDate(errorSummaryRequest.getDate());
        String date = errorSummaryRequest.getDate();

        if (StringUtils.isEmpty(date))
        {
            date = dateHelper.getDate(dateTypeEnum, LocalDate.now(), LocalTime.now(),
                LocalTime.of(processingDateCutOffHour, processingDateCutOffMinute, processingDateCutOffSecond, processingDateCutOffNanoOfSecond));
        }

        ErrorSummaryResponse errorSummaryResponse = new ErrorSummaryResponse();
        ErrorSummaryDetails errorSummaryDetails = new ErrorSummaryDetails();
        errorSummaryResponse.setErrorSummaryDetails(errorSummaryDetails);
        errorSummaryDetails.setCatOrganizationId(errorSummaryRequest.getCatOrganizationId());
        errorSummaryDetails.setProductType(productTypeEnum.getValue());
        errorSummaryDetails.setPerspective(perspectiveEnum.name());
        errorSummaryDetails.setDateType(dateTypeEnum.getValue());
        errorSummaryDetails.setDate(date);

        List<ErrorSummaryDetail> errorSummaryDetailList = errorSummaryDao
            .getErrorSummaryDetails(errorSummaryRequest.getCatOrganizationId(), dateTypeEnum, date, productTypeEnum, perspectiveEnum,
                errorSummaryPostRequest.getStartRow(), errorSummaryPostRequest.getEndRow());
        errorSummaryDetails.setErrorSummaryDetails(errorSummaryDetailList);

        errorSummaryResponse.setLastRow(errorSummaryDetailList.size());
        return errorSummaryResponse;
    }

    /**
     * Validate the date
     *
     * @param dateValue the date value
     */
    protected void validateDate(String dateValue)
    {
        CatddDateUtils.getDateFromStringYYYYMMDD(dateValue);
    }

//    /**
//     * Method that returns date for processing or trade date based on the login time and date of the user
//     *
//     * @param currentTime current time when the user is requesting the error summary
//     * @param cutOffTime cutoff time to decide the processing date for the error summary
//     *
//     * @return the date to be used to get error summary
//     */
//    protected String getDate(DateTypeEnum dateTypeEnum, LocalDate currentDate, LocalTime currentTime, LocalTime cutOffTime)
//    {
//        Instant currentDateInstant = currentDate.atStartOfDay(ZoneId.of(JSON_TIMESTAMP_TIMEZONE)).toInstant();
//
//        String startExpectedPartitionValue = CatddDateUtils
//            .getDateAsStringYYYYMMDD(Date.from(currentDate.minusDays(DAYS_FOR_PARTITION_VALUE).atStartOfDay(ZoneId.of(JSON_TIMESTAMP_TIMEZONE)).toInstant()));
//
//        String endExpectedPartitionValue = CatddDateUtils.getDateAsStringYYYYMMDD(Date.from(currentDateInstant));
//
//        ExpectedPartitionValuesInformation expectedPartitionValuesInformation =
//            herdDao.getExpectedPartitionValues(startExpectedPartitionValue, endExpectedPartitionValue);
//
//        // This list is expected to have more than 3 dates as the date range we are giving is 10 days
//        List<String> list = expectedPartitionValuesInformation.getExpectedPartitionValues();
//
//        return Objects.equals(dateTypeEnum, DateTypeEnum.PROCESSING_DATE) ? getProcessingDate(currentDateInstant, currentTime, cutOffTime, list) :
//            getTradeDate(currentDateInstant, list);
//    }
//
//    /**
//     * Method that returns the processing date as per the business requirement
//     *
//     * @param currentDateInstant current date instant with Eastern timezone
//     * @param currentTime current time when the user is requesting the error summary
//     * @param cutOffTime cutoff time to decide the processing date for the error summary
//     * @param list the list of trade dates from today-10 days till today
//     *
//     * @return the processing date
//     */
//    protected String getProcessingDate(Instant currentDateInstant, LocalTime currentTime, LocalTime cutOffTime, List<String> list)
//    {
//        String processingDate;
//
//        if (CatddDateUtils.getDateFromStringYYYYMMDD(list.get(list.size() - 1)).before(Date.from(currentDateInstant)))
//        {
//            processingDate = list.get(list.size() - 2);
//        }
//        else
//        {
//            processingDate = currentTime.isBefore(cutOffTime) ? list.get(list.size() - 3) : list.get(list.size() - 2);
//        }
//
//        return processingDate;
//    }
//
//    /**
//     * Method that returns the trade date as per the business requirement
//     *
//     * @param currentDateInstant current date instant with Eastern timezone
//     * @param list the list of trade dates from today-10 days till today
//     *
//     * @return the processing date
//     */
//    protected String getTradeDate(Instant currentDateInstant, List<String> list)
//    {
//        return CatddDateUtils.getDateFromStringYYYYMMDD(list.get(list.size() - 1)).before(Date.from(currentDateInstant)) ? list.get(list.size() - 1) :
//            list.get(list.size() - 2);
//    }
}

--------------------------------------------------------------------------


SELECT date, cat_rprtr_imid catImid, cat_sbmtr_id catSubmitterId, rprd_st repairedStatus, err_type errorType, err_cd errorCode, err_ds errorReason,
 COUNT(*) errorCount FROM (SELECT erd.trd_dt date, cat_rprtr_imid, cat_sbmtr_id, rprd_st, err_type, erc.err_cd, ecl.err_ds FROM catdd_owner.err_rec_info eri,
 catdd_owner.err_rec_cd erc, catdd_owner.err_cd_lk ecl WHERE  eri.prdct_type=:productType AND (eri.cat_rprtr_id=:orgId OR eri.cat_sbmtr_id=:orgId) AND
 (eri.trd_dt <= :endDate AND eri.trd_dt >= :startDate) AND eri.err_rec_info_id = erc.err_rec_info_id AND ecl.err_cd= erc.err_cd AND eri.rprd_st='R'
 AND NOT EXISTS (SELECT err_roe_id FROM catdd_owner.pndng_rec_info pri WHERE pri.err_roe_id=eri.err_roe_id) UNION ALL SELECT erd.trd_dt date,
 eri.cat_rprtr_imid, eri.cat_sbmtr_id, eri.rprd_st, eri.err_type, erc.err_cd, ecl.err_ds FROM catdd_owner.err_rec_info eri, catdd_owner.err_rec_cd erc,
 catdd_owner.err_cd_lk ecl, catdd_owner.pndng_rec_info pri WHERE  eri.prdct_type=:productType AND (eri.cat_rprtr_id=:orgId OR eri.cat_sbmtr_id=:orgId)
 AND (eri.trd_dt <= :endDate AND eri.trd_dt >= :startDate) AND eri.err_rec_info_id = erc.err_rec_info_id AND ecl.err_cd= erc.err_cd AND
 eri.err_roe_id = pri.err_roe_id AND eri.rprd_st='R' AND pri.rprd_st='S' UNION ALL SELECT erd.trd_dt date, pri.cat_rprtr_imid, pri.cat_sbmtr_id,
 pri.rprd_st, pri.err_type, erc.err_cd, ecl.err_ds FROM catdd_owner.err_rec_info eri, catdd_owner.err_rec_cd erc, catdd_owner.pndng_rec_info pri,
 catdd_owner.err_cd_lk ecl WHERE  eri.prdct_type=:productType AND (eri.cat_rprtr_id=:orgId OR eri.cat_sbmtr_id=:orgId) AND (eri.trd_dt <= :endDate AND eri.trd_dt >= :startDate) AND
 eri.err_rec_info_id = erc.err_rec_info_id AND (eri.rprd_st='U' OR (eri.rprd_st='R' AND pri.rprd_st='P'))  AND eri.err_roe_id = pri.err_roe_id AND
 ecl.err_cd= erc.err_cd UNION ALL SELECT erd.trd_dt date, cat_rprtr_imid, cat_sbmtr_id, rprd_st, err_type, erc.err_cd, ecl.err_ds
 FROM catdd_owner.err_rec_info eri, catdd_owner.err_rec_cd erc, catdd_owner.err_cd_lk ecl      WHERE  eri.prdct_type=:productType AND
 (eri.cat_rprtr_id=:orgId OR eri.cat_sbmtr_id=:orgId) AND (eri.trd_dt <= :endDate AND eri.trd_dt >= :startDate) AND eri.err_rec_info_id = erc.err_rec_info_id AND eri.rprd_st='U'
 AND ecl.err_cd= erc.err_cd AND NOT EXISTS (SELECT err_roe_id FROM catdd_owner.pndng_rec_info pri WHERE pri.err_roe_id=eri.err_roe_id))
 esr GROUP BY date, cat_rprtr_imid, cat_sbmtr_id, err_type, rprd_st, err_cd, err_ds ORDER BY date, cat_rprtr_imid, cat_sbmtr_id, err_type, rprd_st, err_cd LIMIT 20 OFFSET 1
 
 
 --------------------------------------------------------------------------


Add a logger in Credstash and GetBusinessObjectData

so that retires message would make sense




if the attribute is Not thirdParty or reporterOrgId, and attibute is not present, throw Exception("no value found for required attribute")

if the attribute is Not thirdParty or reporterOrgId, but targetFileName and formatUsage="INT_META", check for resultAttribute.
		If result attibute is Failure, file name should have been present,so throw Exception("no value found for required attribute")
		Else if result attribute is Not Failure, set fileName as null ? 


---------------------------------------------------------------------------------
INSERT INTO catdd_owner.herd_info_lk(
	herd_info_id, actn_type, strg_name, name_space, bus_objct_dfntn, usage_cd, file_type, frmt_vrsn, prtn_key)
	VALUES (2, 'FDBK_DWNLD', 'S3_MANAGED', 'IndustryMember', 'ORDER_EVENTS', 'INT', 'TXT', 0, ?);
	
---------------------------------------------------------

getMessageType -> make a db call, check against businessObjectdata, if present then return new FeedbackProcessor() else return NoOpProcessor().
					--------------> Create a connection, get businessObjectdata, compare. 
				
--------------------------------------------------------------------------------
 @Test
    @Tag("api")
    @Tag("feedback")
    @Publish(name = "Verify roles for getting feedback file details", description = "User and Readonly roles should able to get feedback file details.", coverage = "CATDD-405")
    public void testRoleForgetFeedbackFiles()
    {
        Role role = Role.CAT_PRIV_CATDD_IM_USER;

        Map<String, Object> queryParam = new HashMap<>();
        queryParam.put(QueryParams.CAT_RPRTR_ORG_ID.getValue(), role.getOrgId());
        queryParam.put(QueryParams.START_DATE.getValue(), "");
        queryParam.put(QueryParams.END_DATE.getValue(), "");
        queryParam.put(QueryParams.PERSPECTIVE.getValue(), Perspective.SUBMITTER);

        FeedbackBuilder builder = FeedbackBuilder.build().getFeedbackFiles(queryParam, role.getRole());
        FeedbackFileDetailsOutput actualFeedbackFileDetails = builder.getFeedbackFileDetailsOutput();

        List<FeedbackFileInformationEntity> feedbackFileInformationEntities = feedBackDao.getByQueryParams(queryParam);
        FeedbackFileDetailsOutput expectedFeedbackFileDetails = buildFeedbackFileOutput(feedbackFileInformationEntities, queryParam);
        assertEquals(actualFeedbackFileDetails, expectedFeedbackFileDetails, "Feedback file details are mismatching");
    }

    private FeedbackFileDetailsOutput buildFeedbackFileOutput(List<FeedbackFileInformationEntity> feedbackFileInformationEntityList, Map<String, Object> queryParams)
    {
        List<FeedbackFileDetailOutput> feedbackFileDetailOutputList = feedbackFileInformationEntityList.stream()
                .map((feedbackFileInformationEntity -> convertFeedbackFileInformationEntityToFeedbackFileDetailOutput(feedbackFileInformationEntity)))
            .collect(Collectors.toList());

        FeedbackFileDetailOutput[] feedbackFileDetailOutputs = new FeedbackFileDetailOutput[feedbackFileDetailOutputList.size()];
        feedbackFileDetailOutputs = feedbackFileDetailOutputList.toArray(feedbackFileDetailOutputs);

        FeedbackFileDetailsOutput feedbackFileDetailsOutput = FeedbackFileDetailsOutput.builder().catOrganizationId((Integer) queryParams.get(QueryParams.CAT_RPRTR_ORG_ID.getValue()))
            .startDate((String) queryParams.get(QueryParams.START_DATE.getValue()))
            .endDate((String) queryParams.get(QueryParams.END_DATE.getValue()))
            .perspective((String) queryParams.get(QueryParams.PERSPECTIVE.getValue()))
            .feedbackFileDetailOutputs(feedbackFileDetailOutputs)
            .build();

        return feedbackFileDetailsOutput;
    }

---------------------------------------------------------------------------------------------------------------
SQS message example:
{
    "Records": [
        {
            "messageId": "059f36b4-87a3-44ab-83d2-661975830a7d",
            "receiptHandle": "AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...",
			"{  \"message\" : \"{ \\\"eventDate\\\" : \\\"\\\", \\\"businessObjectDataKey\\\" : { \\\"namespace\\\" : \\\"IndustryMember\\\", \\\"businessObjectDefinitionName\\\" : \\\"ORDER_EVENTS\\\", \\\"businessObjectFormatUsage\\\" : \\\"ING\\\", \\\"businessObjectFormatFileType\\\" : \\\"TXT\\\", \\\"businessObjectFormatVersion\\\" : 0, \\\"partitionValue\\\" : \\\"2019-10-15\\\",\\n \\\"subPartitionValues\\\" : [\"1331_MOTF_20191015_testFilePair_OrderEvents_144443\"] }, \\\"newBusinessObjectDataStatus\\\" : \\\"VALID\\\" , \\\"oldBusinessObjectDataStatus\\\" : \\\"\\\" }\",  \"type\" : \"\",  \"signature\" : \"\",  \"timestamp\" : \"\",\"topicArn\" : \"\",\"messageId\" : \"\",  \"signatureVersion\" : \"1\",  \"unsubscribeURL\" : \"\",  \"signingCertURL\" : \"\"}",
                "ApproximateReceiveCount": "1",
                "SentTimestamp": "1545082649183",
                "SenderId": "AIDAIENQZJOLO23YVJ4VO",
                "ApproximateFirstReceiveTimestamp": "1545082649185"
            },
            "messageAttributes": {},
            "md5OfBody": "098f6bcd4621d373cade4e832627b4f6",
            "eventSource": "aws:sqs",
            "eventSourceARN": "arn:aws:sqs:us-east-2:123456789012:my-queue",
            "awsRegion": "us-east-2"
        }
        
        ]
}
--------------------------------------------------------------------------------------------------------------------
file format and compression, can it be uppercase?

1. Create the file in db table with info that we have at hand.  ***
2. Validation....
		File name format check ***
		File name should not exceed 90 characters ***
		Check if the submitter id matches fip logged in user ***
		File format check(for both meta and data files)... json,csv ***
		Meta files has .meta before file format ***
		File compression type check(.bz2) ***
		
		Do we need to verify imid??? NO ***
		
		File upload size(<1gb) 
		************Couldnt upload more than 10 files********UI part
		************Total size of file <5gb********UI part
		
3. Call DM with herd_info data to get the s3 location
4. upload the file
5. Register to DM


https://stackoverflow.com/questions/336210/regular-expression-for-alphanumeric-and-underscores
--------------------------------------------------------------------------------------------------------------------
if part size is 5MB

Lets say I use 3 Streams,

10000/3 = 3333 ....... Each stream can have upto 3333*5= 16 GB

is the given stream file size divided into 10000 parts....?



Portal -> Endpoint for upload with file			-> store details in db
												-> server-to-s3 -> response from s3
------------------------------------------------------------------------------------------------------------------------

If the submitter from existing is used as thrdparty or submitter in another firm, restrict


		Before                                                       After

1. If existing record(based on imid),						If existing record(based on imid),
	check(new submitter = old submitter)						check(new submitter = old submitter)
	and check(new thrdparty = old thrdparty)						or check(new thrdparty = old submitter)
	Exception if true													Exception if true                          If existing record(based on imid)
																													check(new submitter = old thrdparty)
																														or check(new thrdparty = old thrdparty)	
																															Exception if true


			
Same submitter, different third party........ or no third-party(in both existing and new)........or new has third-party, existing doesnt
check(new Expiration date > old expiration date) -> Third Party relationship can not exist beyond submitter relationship


					New																			Existing
orgId				79																				7059(same org, response -> 1), 79(diff org, response -> 2)
imid				ABC																				ABC
Submitter			999																				999		
third				111																				222
effective			10-04-2019																	09-04-2019
expiration			10-25-2019																	10-20-2019

					Response	1.Third Party relationship can not exist beyond submitter relationship
				OR	Response	2.IMID/Submitter Relationship Already Exits. Please Contact FINRA CAT Help Desk %S for Assistance. 

---------------------------------------------------------------------------------------------------------------------------------------------------------------

					New																			Existing
orgId				79																				7059(same org, response -> 1), 79(diff org, response -> 2)
imid				ABC																				ABC				
Submitter			999																				999			
third																								
effective			10-04-2019																	09-04-2019
expiration			10-25-2019																	10-20-2019
				
					Response	1.Relationship Already Exists
				OR	Response	2.IMID/Submitter Relationship Already Exits. Please Contact FINRA CAT Help Desk %S for Assistance. 

---------------------------------------------------------------------------------------------------------------------------------------------------------------

					New																			Existing(same org, response -> 1), 79(diff org, response -> 2)
orgId				79																				7059
imid				ABC																				ABC		
Submitter			999																				999			
third				123																				123
effective			10-04-2019																	09-04-2019
expiration			10-25-2019																	10-20-2019

					Response	1.Relationship Already Exists
				OR	Response	2.IMID/Submitter Relationship Already Exits. Please Contact FINRA CAT Help Desk %S for Assistance. 

---------------------------------------------------------------------------------------------------------------------------------------------------------------

					New																			Existing
orgId				79																				7059
imid				ABC																				ABC
Submitter			999																				999
third				111																				
effective			10-04-2019																	09-04-2019
expiration			10-25-2019																	10-20-2019

							Third Party relationship can not exist beyond submitter relationship
				OR			IMID/Submitter Relationship Already Exits. Please Contact FINRA CAT Help Desk %S for Assistance.
-----------------------------------------------------------------------------------------------------------------------------------------------------

Same submitter, new has no third-party, existing has third-party
check(new Expiration date < old expiration date) -> Expiring Submitter relationship while Third Party relationship exists beyond submitter relationship 
																												OR IMID/Submitter Relationship...........
				New																			Existing
orgId				79																				88
imid				ABC																				ABC
Submitter			999																				999
third																								222
effective			10-04-2019																	09-04-2019
expiration			10-18-2019																	10-20-2019
	
			
			
If(orgId_old = org_idnew & submitter_old = submitter_new   AND  (third-party_old=null & third-party_new!=null) ->call checker...adding child...
If(orgId_old = org_idnew & submitter_old = submitter_new   AND  (third-party_old!=null & third-party_new=null) ->call checker...adding parent...

If(submitter_old = submitter_new   AND  (third-party_old=abc & third-party_new=def OR newthirdpaty=oldthirdparty) ->new exception...


--------------------------------------------------------------------
File_submission table	-> no change

Herd_info_lookup_table		-> removed constraint

status_lookup_table		-> added a grant

feedback_table	-> added

herd_sequence -> added

feedback_sequence -> added

----------------------------------------------------
File uploaded at 1pm, shows 6pm. because when I just save the local time, it saves in utc,

-----------------------------------------------------

1. Add all feedbacks to a list. then execute send the list. After connection, add a for loop or stream the list and after that commit. ***

2. When we add to the herd_table what is the partition key gonna be? only compare with the rest except partition key ???	***

3. Where is the return ignore.name() enum going to

4. Sequence naming.... Sequence review...... Add into.....	***

5. remove propertyUtility and lambdaTest	***

6. redundant true???? controller ***

7. GetHerdInfo() instead of checkHerdInfo(). Rename in lambda, and java doc too.

https://wiki.finra.org/display/DataManagement/Business+Object+Data+Status+Change+Event+Notification

---------------------------------------------------------------------------------------------
File upload:

1. ApacheCommons stream to disk, FileItem coverted to file, then transferManager to upload file to s3 -> FAIL in the middle for 1gb file, OK for smaller files. Multipart(YES)
2. ApacheCommons stream to disk, then transferManager to upload stream to s3 -> 1gb file (Avg upload time : 2:44) , Multipart(YES), Thread not seem to be having effect
	2:39, 2:30, 2:54, 2:51

3. ApacheCommons stream to server then transferManager to upload stream to s3(No content length) -> 1gb file (Avg upload time : 2:28) , SinglePart
	2:08, 2:46, 2:23, 2:36
4. ApacheCommons stream to server then transferManager to upload stream to s3(Yes content length) -> 1gb file (Avg upload time : 2:01) , SinglePart
	2:18, 1:50, 1:56, 2:02
		
	Came to a conclusion that some ways above using multipart because of TRANSFER_PART_COMPLETED_EVENT log in progressListener
	
	Questions:
	1. How do we verify if it is actually using a multipart upload?
	2. Best way to get the content-length for metadata when we are streaming to s3 using transferManager?
	3. Use streaming using apache commons and store in an EFS, then put to s3. Using stream does it do multipart? or using the file?
	
-------------------------------------------------------------------------------------------------------------------------------------------------------------

1.   Client -> Server (Apache Commons streaming)         &       Server -> s3 (Transfer Manager - singlePart - Streaming)

		fileSize|   Wifi	| Ethernet  |Content-length
		  1 GB	|			|	 :31    |	NO
				|			|	 :28    |		
				|			|	 :26    |		
				|			|	 :28    |		
	  -----------------------------------------------
				|			|	 :52    |	YES
				|			|	1:06    |		
				|			|	 :51    |	
						
   -> Content-length can only be known if client supplies it as a header but we want to avoid that.
   -> Another way to get the content length is to buffer the stream into the memory and get the size which defeats the whole purpose of streaming.   

******************************************************************************************************************************************************************

2. Client -> Server (Apache commons file upload)           Save to a disk or EFS			Server -> S3 (Transfer manager  -> Stream or file)
	
	a)upload STREAM from server to S3
															 |}
		   fileSize    	|		    Wifi(timeToUpload)		 |}    EthernetCable(timeToUpload)   |
						----------------------------------------------------------------------------------------
						| Client-Server | Server-S3	| total	 |} Client-Server |  Server-S3   | total
		------------------------------------------------------------------------------------------------------
		  1 GB			|	 	0:25	|	2:33	|	2:58 |}		0:24 	  |		0:52     | 1:16		
						|		0:25	|	2:11	|	2:36 |}		0:25 	  | 	1:15     | 1:40
						|				|			|		 |}		0:25  	  |		1:07     | 1:32
						|				|			|		 |}		0:24  	  |		1:04     | 1:28		
															 |}
						
	b)upload FILE from server to S3
													 |}
		   fileSize    	|		    Wifi(timeToUpload)		 |}    EthernetCable(timeToUpload)   |
						----------------------------------------------------------------------------------------
						| Client-Server | Server-S3	| total	 |} Client-Server |  Server-S3   | total
		------------------------------------------------------------------------------------------------------
		  1 GB			|	 			|			|		 |}		0:24 	  |		0:18     | 0:42		
						|				|			|		 |}		0:24 	  | 	0:18     | 0:42
						|				|			|		 |}		0:23  	  |		0:19     | 0:42
						|				|			|		 |}		0:24  	  |		0:19     | 0:43		
															 |}
	
  
   -> Reasonably the best way to do file upload. People use Lambdas to achieve this
   -> On average, to upload a 1gb file it takes about --> Streaming(1 minutes 58 seconds,1:56, 2:11 | Ethernet: 1:26,1:19, 1:17; ), file(1 minutes 2 seconds, 1:09 | Ethernet: 43,51,42)                          		   
   -> temp file not deleted after upload had completed ???? have to explicitly do item.delete();
   -> Does Stream do multipart? or just file?
   
******************************************************************************************************************************************************************  
3. Client -> Server (Apache Commons streaming) 								   Server -> s3 (Transfer Manager - in chunks - multipart streaming)


????????????????????????????????????????????????



******************************************************************************************************************************************************************
4. Client -> server(storing in disk)..................Server->(s3)

Uploading 1 gb file on average takes : 50 seconds

-----------------------------------------------------------------------------------------------------------------------------
5. Store in memory if less than 20MB, else store it in a disk temporarily, then use transferManager to upload to s3(James)
			   fileSize    	|		    Wifi(timeToUpload)		 |}    EthernetCable(timeToUpload)   |
						----------------------------------------------------------------------------------------
						| Client-Server | Server-S3	| total	 |} Client-Server |  Server-S3   | total 
		------------------------------------------------------------------------------------------------------
		  1 GB			|	 			|			|		 |}		0:46 	  |		0:15     | 1:01		
						|				|			|		 |}		0:42 	  | 	0:16     | 0:58
						|				|			|		 |}		0:42  	  |		0:15     | 0:57
						|				|			|		 |}		0:43  	  |		0:14     | 0:57	

-----------------------------------------------------------------------------------------------------------------------------
Streaming...................store upto 5MB, mark the position, then upload that chunk, come back and store another chunk, repeat...

Client to server time, server to s3 time 

---------------------------------------------------------------------------------------------------------------------------------------------------------------
FIle name validation scenarios:

DATA FILE:

2022_MYID_20170101_FileGroup1_OrderEvents_000123.csv.bz2     	PASS																			***
2022_MYID_20170101_FileGroup1_OrderEvents_000123.json.bz2		PASS																			***
2022_MYID_20170101_FileGroup1_OrderEvents_000123.dav.bz2		FAIL -> File Format incorrect													***
2022_MYID_20170101_FileGroup1_OrderEvents_000123.csv.xx3		FAIL -> Compression type incorrect												***
2022_MYID_20170101_OrderEvents_000123.csv.bz2					PASS									(Optional group)						***
2022_MYID_20170101_OrderEvents_000123.json.bz2					PASS									(Optional group)						***
2022_MYID_20170101_OrderEvents_000123.dav.bz2					FAIL -> File Format incorrect													***
2022_MYID_20170101_OrderEvents_000123.csv.xx3					FAIL -> Compression type incorrect												***
1111_MYID_20170101_FileGroup1_OrderEvents_000123.csv.bz2		FAIL -> Unauthorized user														***
1111_MYID_20170101_OrderEvents_000123.csv.bz2					FAIL -> Unauthorized user				(Optional group)						***
2022_MYID_20170101_FileGroup1_000123.csv.bz2					FAIL -> File name format incorrect			(missing fileKind)					???
2022_MYID_20170101_FileGroup1_OrderEvents.csv.bz2				FAIL -> File name format incorrect			(missing fileNumber)				***
2022_MYID_FileGroup1_OrderEvents_000123.csv.bz2					FAIL -> File name format incorrect			(missing file generation date)		***
2222_20170101_FileGroup1_OrderEvents_000123.csv.bz2				FAIL -> File name format incorrect			(missing imid)						***
MYID_20170101_FileGroup1_OrderEvents_000123.csv.bz2				FAIL -> File name format incorrect			(missing orgid)						***
20170101_FileGroup1_OrderEvents_000123.csv.bz2					FAIL -> File name format incorrect			(missing orgid and imid)			***
2222_20170101_OrderEvents_000123.csv.bz2						FAIL -> File name format incorrect			(missing imid and group)			***
2222_20170101_FileGroup1_000123.csv.bz2							FAIL -> File name format incorrect			(missing imid and fileKind)			***		

META FILE:
2022_MYID_20170101_FileGroup1_OrderEvents_000123.meta.csv     	PASS																												****
2022_MYID_20170101_FileGroup1_OrderEvents_000123.meta.json		PASS																												****
2022_MYID_20170101_FileGroup1_OrderEvents_000123.meta.dav		FAIL -> File Format incorrect																						****
2022_MYID_20170101_FileGroup1_OrderEvents_000123.dell.csv		FAIL ->	**Tricky part.If no meta. It is like data file with dell format...file format incorrect						****
2022_MYID_20170101_OrderEvents_000123.meta.csv					PASS									(Optional group)															****
2022_MYID_20170101_OrderEvents_000123.meta.json					PASS									(Optional group)															****
2022_MYID_20170101_OrderEvents_000123.meta.dav					FAIL -> Format incorrect																							****
2022_MYID_20170101_OrderEvents_000123.dell.csv					FAIL -> **Tricky part.If no meta. It is like data file with dell format...file format incorrect						****
1111_MYID_20170101_FileGroup1_OrderEvents_000123.meta.csv		FAIL -> Unauthorized user               																			****
1111_MYID_20170101_OrderEvents_000123.meta.csv					FAIL -> Unauthorized user				(Optional group)															****
2022_MYID_20170101_FileGroup1_000123.meta.csv					FAIL -> File name format incorrect			(missing fileKind)														????
2022_MYID_20170101_FileGroup1_OrderEvents.meta.csv				FAIL -> File name format incorrect			(missing fileNumber)													****
2022_MYID_20170101_FileGroup1_OrderEvents.meta.csv				FAIL -> File name format incorrect			(missing file generation date)											****
2222_20170101_FileGroup1_OrderEvents_000123.meta.csv			FAIL -> File name format incorrect			(missing imid)															****
MYID_20170101_FileGroup1_OrderEvents_000123.meta.csv			FAIL -> File name format incorrect			(missing orgid)															****
20170101_FileGroup1_OrderEvents_000123.meta.csv					FAIL -> File name format incorrect			(missing orgid and imid)												****
2222_20170101_OrderEvents_000123.meta.csv						FAIL -> File name format incorrect			(missing orgid and group)												****
2222_20170101_FileGroup1_000123.meta.csv						FAIL -> File name format incorrect			(missing imid and fileKind)		
-----------------------------------------------------------------------------------------------------------------------------------
05/20/2019
* Implement REST endpoint to CREATE ATS Order Types:

      1.Expiration Date (required) - this must be a timestamp date
	Effective Date (required) - this must be a timestamp date
        ----------------------------------------------------------> No Timestamp, only date ????
      2.Lets say for IMID, if provided a special characters, how is the response gonna look like, error code, or msg?
      3.Same combination of AtsOrderType and IMID replaces the existing record.
	How should we do it?
